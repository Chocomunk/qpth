{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# import qpth.solvers.dynamic.solve as dynamic_solver\n",
    "from qpth.util import get_sizes, extract_nBatch, expandParam\n",
    "from qpth.solvers import cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(Q, p, G, h, A, b, verbose=0, maxIter=100, dt=0.2):\n",
    "    nineq, nz, neq, nBatch = get_sizes(G, A)\n",
    "\n",
    "    # Base inverses and transposes\n",
    "    Q_I = torch.inverse(Q)\n",
    "    G_T = torch.transpose(G, -1, 1)\n",
    "    A_T = torch.transpose(A, -1, 1)\n",
    "\n",
    "    # Intermediate matrix expressions\n",
    "    GQ_I = - G.bmm(Q_I)             # - G Q^{-1}\n",
    "    AQ_I = - A.bmm(Q_I)             # - A Q^{-1}\n",
    "    GA = GQ_I.bmm(A_T)              # - G Q^{-1} A^T\n",
    "    GG = GQ_I.bmm(G_T)              # - G Q^{-1} G^T\n",
    "    AA = AQ_I.bmm(A_T)              # - A Q^{-1} A^T\n",
    "    AG = AQ_I.bmm(G_T)              # - A Q^{-1} G^T\n",
    "    la_d = GQ_I.bmm(p.unsqueeze(2)) - h.unsqueeze(2)       # - G Q^{-1} p - h\n",
    "    nu_d = AQ_I.bmm(p.unsqueeze(2)) - b.unsqueeze(2)       # - A Q^{-1} p - b\n",
    "\n",
    "    lams = torch.zeros(nBatch, nineq, 1).type_as(Q).to(Q.device)\n",
    "    nus = torch.zeros(nBatch, neq, 1).type_as(Q).to(Q.device)\n",
    "    zeros = torch.zeros(nBatch, nineq, 1).type_as(Q).to(Q.device)\n",
    "\n",
    "    for _ in range(maxIter):\n",
    "        dlams = dt * (GG.bmm(lams) + GA.bmm(nus) + la_d)\n",
    "        dnus = dt * (AG.bmm(lams) + AA.bmm(nus) + nu_d)\n",
    "        dlams = torch.max(lams + dlams, zeros) - lams\n",
    "        lams.add_(dlams)\n",
    "        nus.add_(dnus)\n",
    "\n",
    "    zhat = - Q_I.bmm(p.unsqueeze(2) + G_T.bmm(lams) + A_T.bmm(nus))\n",
    "    slacks = h.unsqueeze(2) - G.bmm(zhat)\n",
    "    \n",
    "    return zhat.squeeze(2), lams.squeeze(2), nus.squeeze(2), slacks.squeeze(2)\n",
    "\n",
    "def forward_ineq(H, c, A, b, verbose=0, maxIter=100, dt=0.2):\n",
    "    nineq, nz, neq, nBatch = get_sizes(A)\n",
    "    A_T = torch.transpose(A, -1,1)\n",
    "    H_I = torch.inverse(H)\n",
    "\n",
    "    AH_I = A.bmm(H_I)\n",
    "    D = - AH_I.bmm(A_T)\n",
    "    d = - (b.unsqueeze(2) + AH_I.bmm(c.unsqueeze(2)))\n",
    "\n",
    "    y = torch.zeros(nBatch, nineq, 1).type_as(H).to(H.device)\n",
    "    zeros = torch.zeros(nBatch, nineq, 1).type_as(H).to(H.device)\n",
    "\n",
    "    for _ in range(maxIter):\n",
    "        dy = dt * (D.bmm(y) + d)\n",
    "        dy = torch.max(y + dy, zeros) - y\n",
    "        y.add_(dy)\n",
    "\n",
    "    zhat = - H_I.bmm(c.unsqueeze(2) + A_T.bmm(y))\n",
    "    slacks = b.unsqueeze(2) - A.bmm(zhat)\n",
    "    \n",
    "    return zhat.squeeze(2), y.squeeze(2), slacks.squeeze(2)\n",
    "\n",
    "def forward_eq_conv(H, c, G_, h_, A_, b_, verbose=0, maxIter=100, dt=0.2):\n",
    "    nineq, nz, neq, nBatch = get_sizes(G_, A_)\n",
    "\n",
    "    A = torch.cat((G_, A_, -A_), dim=1)\n",
    "    b = torch.cat((h_, b_, -b_), dim=1)\n",
    "    A_T = torch.transpose(A, -1,1)\n",
    "    H_I = torch.inverse(H)\n",
    "\n",
    "    AH_I = A.bmm(H_I)\n",
    "    D = - AH_I.bmm(A_T)\n",
    "    d = - (b.unsqueeze(2) + AH_I.bmm(c.unsqueeze(2)))\n",
    "\n",
    "    y = torch.zeros(nBatch, nineq + neq + neq, 1).type_as(H).to(H.device)\n",
    "    zeros = torch.zeros(nBatch, nineq + neq + neq, 1).type_as(H).to(H.device)\n",
    "\n",
    "    for _ in range(maxIter):\n",
    "        dy = dt * (D.bmm(y) + d)\n",
    "        dy = torch.max(y + dy, zeros) - y\n",
    "        y.add_(dy)\n",
    "\n",
    "    zhat = - H_I.bmm(c.unsqueeze(2) + A_T.bmm(y))\n",
    "    slacks = b.unsqueeze(2) - A.bmm(zhat)\n",
    "    \n",
    "    return zhat.squeeze(2), y.squeeze(2)[:,:nineq], y.squeeze(2)[:,-neq:], slacks.squeeze(2)\n",
    "\n",
    "def forward_cvxpy(Q_, p_, G_, h_, A_, b_):\n",
    "    nBatch = extract_nBatch(Q_, p_, G_, h_, A_, b_)\n",
    "    Q, _ = expandParam(Q_, nBatch, 3)\n",
    "    p, _ = expandParam(p_, nBatch, 2)\n",
    "    G, _ = expandParam(G_, nBatch, 3)\n",
    "    h, _ = expandParam(h_, nBatch, 2)\n",
    "    A, _ = expandParam(A_, nBatch, 3)\n",
    "    b, _ = expandParam(b_, nBatch, 2)\n",
    "\n",
    "    check_Q_spd = True\n",
    "    if check_Q_spd:\n",
    "        for i in range(nBatch):\n",
    "            e, _ = torch.eig(Q[i])\n",
    "            if not torch.all(e[:,0] > 0):\n",
    "                raise RuntimeError('Q is not SPD.')\n",
    "\n",
    "    _, nineq, nz = G.size()\n",
    "    neq = A.size(1) if A.nelement() > 0 else 0\n",
    "    assert(neq > 0 or nineq > 0)\n",
    "\n",
    "    vals = torch.Tensor(nBatch).type_as(Q)\n",
    "    zhats = torch.Tensor(nBatch, nz).type_as(Q)\n",
    "    lams = torch.Tensor(nBatch, nineq).type_as(Q)\n",
    "    nus = torch.Tensor(nBatch, neq).type_as(Q) \\\n",
    "        if neq > 0 else torch.Tensor()\n",
    "    slacks = torch.Tensor(nBatch, nineq).type_as(Q)\n",
    "    for i in range(nBatch):\n",
    "        Ai, bi = (A[i], b[i]) if neq > 0 else (None, None)\n",
    "        vals[i], zhati, nui, lami, si = cvxpy.forward_single_np(\n",
    "            *[x.cpu().numpy() if x is not None else None\n",
    "            for x in (Q[i], p[i], G[i], h[i], Ai, bi)])\n",
    "        # if zhati[0] is None:\n",
    "        #     import IPython, sys; IPython.embed(); sys.exit(-1)\n",
    "        zhats[i] = torch.Tensor(zhati)\n",
    "        lams[i] = torch.Tensor(lami)\n",
    "        slacks[i] = torch.Tensor(si)\n",
    "        if neq > 0:\n",
    "            nus[i] = torch.Tensor(nui)\n",
    "\n",
    "    return zhats, lams, nus, slacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data from: https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Quadratic_Programming.pdf\n",
    "\n",
    "p = torch.tensor([1, -2, 4], dtype=torch.float).unsqueeze(0).cuda()\n",
    "Q = torch.tensor([[2,0,1],[0,4,0],[1,0,6]], dtype=torch.float).unsqueeze(0).cuda()\n",
    "h = torch.tensor([10, -2, 5, 5, 5, 0, 1, 0], dtype=torch.float).unsqueeze(0).cuda()\n",
    "G = torch.tensor([\n",
    "    [3, 4, -2],\n",
    "    [2, -2, -1],\n",
    "    [1, 0, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1],\n",
    "    [-1, 0, 0],\n",
    "    [0, -1, 0],\n",
    "    [0, 0, -1]\n",
    "], dtype=torch.float).unsqueeze(0).cuda()\n",
    "b = torch.tensor([5], dtype=torch.float).unsqueeze(0).cuda()\n",
    "A = torch.tensor([\n",
    "    [2, 3, 4]\n",
    "], dtype=torch.float).unsqueeze(0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "58 ms ± 3.21 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\ntensor([[0.3947, 1.3895, 0.0105]], device='cuda:0')\ntensor([[0.0000, 0.1716, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       device='cuda:0')\ntensor([[-1.0716]], device='cuda:0')\ntensor([[ 3.2789e+00, -3.5763e-07,  4.6053e+00,  3.6105e+00,  4.9895e+00,\n          3.9474e-01,  2.3895e+00,  1.0526e-02]], device='cuda:0')\n"
    }
   ],
   "source": [
    "# Standard Forward\n",
    "\n",
    "%timeit forward(Q, p, G, h, A, b, maxIter=40)\n",
    "zhat, lams, nus, slacks = forward(Q, p, G, h, A, b, maxIter=40)\n",
    "\n",
    "print(zhat)\n",
    "print(lams)\n",
    "print(nus)\n",
    "print(slacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "77.8 ms ± 8.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\ntensor([[-1.9730e+16, -1.4202e+16, -6.4037e+14]], device='cuda:0')\ntensor([[7.0916e+15, 0.0000e+00, 1.3037e+15, 1.1712e+15, 1.2346e+15, 7.3825e+14,\n         1.1874e+14, 0.0000e+00]], device='cuda:0')\ntensor([[0.]], device='cuda:0')\ntensor([[ 1.1472e+17,  1.0415e+16,  1.9730e+16,  1.4202e+16,  6.4037e+14,\n         -1.9730e+16, -1.4202e+16, -6.4037e+14,  8.4629e+16, -8.4629e+16]],\n       device='cuda:0')\n"
    }
   ],
   "source": [
    "# Convert eq to ineq\n",
    "\n",
    "%timeit forward_eq_conv(Q, p, G, h, A, b, maxIter=100)\n",
    "zhat, lams, nus, slacks = forward_eq_conv(Q, p, G, h, A, b, maxIter=100)\n",
    "\n",
    "print(zhat)\n",
    "print(lams)\n",
    "print(nus)\n",
    "print(slacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "24.3 ms ± 2.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\ntensor([[0.3947, 1.3895, 0.0105]], device='cuda:0')\ntensor([[ 0.0000e+00,  1.7158e-01,  0.0000e+00,  0.0000e+00, -1.6051e-15,\n          1.0195e-21,  8.0256e-16, -1.1282e-21]], device='cuda:0')\ntensor([[-1.0716]], device='cuda:0')\ntensor([[3.2789e+00, 1.6856e-22, 4.6053e+00, 3.6105e+00, 4.9895e+00, 3.9474e-01,\n         2.3895e+00, 1.0526e-02]], device='cuda:0')\n"
    }
   ],
   "source": [
    "# CVXPY\n",
    "\n",
    "%timeit forward_cvxpy(Q, p, G, h, A, b)\n",
    "zhat, lams, nus, slacks = forward_cvxpy(Q, p, G, h, A, b)\n",
    "\n",
    "print(zhat)\n",
    "print(lams)\n",
    "print(nus)\n",
    "print(slacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitcs159conda5739f4b666d44eb9afad7229d8e1fa2f",
   "display_name": "Python 3.8.2 64-bit ('cs159': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}